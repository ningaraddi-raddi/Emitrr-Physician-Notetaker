# ğŸ©º Physician Notetaker â€“ AI Medical Documentation System

An end-to-end AI pipeline that automatically converts doctor-patient conversations into structured **SOAP notes** using NLP and transformer-based models.

---

## ğŸ“˜ Table of Contents

1. [Overview](#overview)  
2. [System Architecture](#system-architecture)  
3. [Key Components](#key-components)  
4. [Tech Stack](#tech-stack)  
5. [Why Pretrained Models Are Used](#why-pretrained-models-are-used)  
6. [Installation](#installation)  
7. [Usage](#usage)  
8. [Project Structure](#project-structure)  
9. [Limitations](#limitations)  
10. [Future Work](#future-work)

---

## ğŸ©º Overview

**Physician Notetaker** automates medical documentation by processing raw doctor-patient transcripts and generating structured SOAP notes.  
The system uses a hybrid approach combining **BioBERT transformers** with **rule-based NLP methods**.

### Key Features

- ğŸ§  **Hybrid NER System** â€“ Combines BioBERT + scispaCy for robust entity extraction  
- ğŸ’¬ **Multi-Task Learning** â€“ Joint sentiment and intent classification  
- ğŸ“‹ **Auto SOAP Notes** â€“ Structured clinical documentation  
- âš™ï¸ **Modular Pipeline** â€“ Independent, reusable components  

---

## ğŸ§© System Architecture

```text
Doctor-Patient Transcript
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. NER Extraction     â”‚  â†’ Extract symptoms, diagnosis, treatment
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. Summarization      â”‚  â†’ Generate structured medical summary
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. Sentiment/Intent   â”‚  â†’ Analyze patient emotion & purpose
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. SOAP Generation    â”‚  â†’ Build clinical note (S.O.A.P format)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
    SOAP Note Output
ğŸ§  Key Components
1. Named Entity Recognition (NER)
BioBERT Transformer â€“ Pre-trained on 470K+ medical papers

scispaCy â€“ Rule-based pattern matching with 100K+ medical terms

Regex Patterns â€“ Extract measurements, dates, and quantities

Output: Symptoms, Diagnosis, Treatment, Prognosis

2. Medical Summary Generation
Deduplicates and cleans extracted entities

Extracts patient information using regex

Maps entities to medical categories

Output: Structured JSON summary

3. Sentiment & Intent Analysis
Multi-task BioBERT classifier with two heads:

Sentiment: Anxious / Neutral / Reassured

Intent: Reporting / Seeking / Expressing / Confirming

Fine-tuned on domain-relevant conversation samples

Output: Patient emotional state and conversation intent

4. SOAP Note Generation
S (Subjective): Patient complaints & history

O (Objective): Doctor observations & exam findings

A (Assessment): Diagnosis & clinical impression

P (Plan): Treatment & follow-up recommendations

Output: Clinical SOAP note in JSON format

âš™ï¸ Tech Stack
Component	Technology	Purpose
NER	BioBERT (d4data/biomedical-ner-all)	Medical entity extraction
Secondary NER	scispaCy (en_core_sci_md)	Rule-based patterns
Sentiment/Intent	Fine-tuned BioBERT	Emotion & intent classification
Framework	HuggingFace Transformers, PyTorch	Deep learning
NLP Tools	spaCy 3.7+	Text processing

ğŸ§  Why Pretrained Models Are Used
We adopted pretrained biomedical transformers like BioBERT and scispaCy because medical NLP tasks require understanding highly domain-specific language and terminology that are not captured by general NLP models.
Training from scratch would demand millions of medical records and heavy computation.

By using pretrained models, we leverage transfer learning, where models trained on vast biomedical literature already understand the context of clinical language.
Fine-tuning them on smaller, task-specific datasets provides strong performance even with limited labeled data.

Key Reasons
ğŸ©¸ Domain-Specific Vocabulary: Medical dialogues include terms and abbreviations like HbA1c, BP, dyspnea, metformin, etc., which pretrained biomedical models already understand.

ğŸ’° Reduced Training Cost: Avoids training from scratch, saving time and compute resources.

ğŸ§© Improved Contextual Understanding: BioBERT captures relationships between symptoms, diagnoses, and treatments with contextual accuracy.

ğŸ” Transfer Learning Advantage: Pretrained biomedical models generalize better on unseen medical conversations.

Summary
Task	Model Used	Purpose
NER Extraction	BioBERT (d4data/biomedical-ner-all)	Extracts entities like Symptoms, Diagnosis, and Treatment
Supplementary NER	scispaCy (en_core_sci_md)	Enhances coverage through rule-based medical term matching
Sentiment & Intent Analysis	Fine-tuned BioBERT	Detects patient emotions and conversational intent
SOAP Generation	Rule-based Template + Transformer Output	Creates structured clinical documentation

Note: Evaluation metrics have been intentionally excluded.
The focus of this version is to demonstrate a functioning AI documentation pipeline, not model benchmarking.
Future iterations will include validation on real-world doctor-patient datasets.

ğŸ§° Installation
Step 1: Clone Repository
bash
Copy code
git clone https://github.com/yourusername/Physician-Notetaker.git
cd Physician-Notetaker
Step 2: Create Virtual Environment
bash
Copy code
python -m venv venv
source venv/bin/activate      # macOS/Linux
venv\Scripts\activate         # Windows
Step 3: Install Dependencies
bash
Copy code
pip install -r requirements.txt
Step 4: Download Models
bash
Copy code
python -m spacy download en_core_web_sm
python -m spacy download en_core_sci_md
python -m spacy validate
â–¶ï¸ Usage
Run Full Pipeline
bash
Copy code
python src/pipeline_runner.py --input data/sample_transcript.txt
Output:

output/ner_results.json â€“ Extracted entities

output/summary.json â€“ Medical summary

output/sentiment_results.json â€“ Sentiment/intent

output/soap_note.json â€“ Final SOAP note

Run Individual Components
bash
Copy code
# 1. NER Extraction
python src/ner_extractor.py --input data/sample_transcript.txt

# 2. Summarization
python src/summarizer.py --transcript data/sample_transcript.txt --ner_output output/ner_results.json

# 3. Sentiment Analysis
python src/sentiment_analyzer.py --input data/sample_transcript.txt

# 4. SOAP Generation
python src/soap_generator.py --ner output/ner_results.json --summary output/summary.json --sentiment output/sentiment_results.json
ğŸ“ Project Structure
pgsql
Copy code
Physician-Notetaker/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sample_transcript.txt
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ner_extractor.py
â”‚   â”œâ”€â”€ summarizer.py
â”‚   â”œâ”€â”€ sentiment_analyzer.py
â”‚   â”œâ”€â”€ soap_generator.py
â”‚   â””â”€â”€ pipeline_runner.py
â”œâ”€â”€ output/
â”‚   â”œâ”€â”€ ner_results.json
â”‚   â”œâ”€â”€ summary.json
â”‚   â”œâ”€â”€ sentiment_results.json
â”‚   â””â”€â”€ soap_note.json
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
âš ï¸ Limitations
Current models trained/fine-tuned on synthetic or limited data

Rule-based SOAP generation may lack flexibility for complex cases

Real-world validation required for robust deployment
